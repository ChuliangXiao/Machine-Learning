---
title: "Decision Tree and Random Forest"
subtitle: "Test case with the `iris` data"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# A test case with the `iris` data  

The `datasets::iris` is a basic data set in R provided by [UCI's R.A. Fisher](https://archive.ics.uci.edu/ml/datasets/iris) 

## Load libraries
```{r library, message = F, warning = F}
library(tidyverse)
library(rpart)
library(randomForest)
library(caret)       # used to split the data
```

## Iris data description  
```{r iris data description}
str(iris)
summary(iris)
#Hmisc::describe(iris)
```


## A quick look at the data
```{r quick plot, fig.width = 10}
#qplot(Petal.Length, Petal.Width, colour = Species, data = iris)
#qplot(Sepal.Length, Sepal.Width, colour = Species, data = iris)
p1 <- ggplot(iris, aes(Petal.Length, Petal.Width)) + 
  geom_point(aes(color = Species)) +
  theme(legend.position = "top")
p2 <- ggplot(iris, aes(Sepal.Length, Sepal.Width)) + 
  geom_point(aes(color = Species)) +
  theme(legend.position = "top")
gridExtra::grid.arrange(p1, p2, ncol = 2)
```


## Split the data into the _Train_ part and the _Test_ part
```{r Split iris data}
set.seed(1234)
ind   <- createDataPartition(iris$Species, p = .5, list = FALSE)
Train <- iris[ind, ]
Test  <- iris[-ind, ]
```


## Decision Tree model from `rpart`
```{r DT Model}
fitDT   <- train(Species ~ ., method = "rpart", data = Train)
```

### Validate and Test the DT model
```{r Validat DT}
#Validate againt the Train data part
predDT  <- predict(fitDT, Train)
table(predDT, Train$Species)
#Validate againt the Test data part
testDT  <- predict(fitDT, Test)
table(testDT, Test$Species)
```

### Look into the DT model 
```{r plot DT}
library(rpart.plot)
rpart.plot(fitDT$finalModel)
```

### Where are the misclassifications  
```{r misclassifications, fig.width = 10}
pred_spec <- data.frame(pred_spec = predDT)
Train_c <- Train %>% 
  bind_cols(pred_spec) %>% 
  mutate(classify  = (pred_spec == Species))

g1 <- ggplot(Train_c, aes(Petal.Length, Petal.Width, color = classify)) + 
  geom_point(aes(shape = pred_spec)) +
  geom_jitter() +
  theme(legend.position = "top")

g2 <- ggplot(Train_c, aes(Sepal.Length, Sepal.Width, color = classify)) + 
  geom_point(aes(shape = pred_spec)) +
  geom_jitter() +
  theme(legend.position = "top")
gridExtra::grid.arrange(g1, g2, ncol = 2)
```
The

## Random Forest model from `randomForest`
```{r RF Model}
set.seed(2345)
fitRF   <- train(Species ~ ., method = "rf", data = Train)
```

### Validate and Test the model
```{r Validate RF}
#Validate againt the Train data part
predRF  <- predict(fitRF, Train)
table(predRF, Train$Species)
#Validate againt the Test data part
testRF  <- predict(fitRF, Test)
table(testRF, Test$Species)
```

## Uneven split
```{r Uneven split}
set.seed(1000)
ind1   <- createDataPartition(iris$Species, p = .8, list = FALSE)
Train1 <- iris[ind1, ]
Test1  <- iris[-ind1, ]

fitDT1   <- train(Species ~ ., method = "rpart", data = Train1)

#Validate againt the Train data part
predDT1  <- predict(fitDT1, Train1)
table(predDT1, Train1$Species)
#Validate againt the Test data part
testDT1  <- predict(fitDT1, Test1)
table(testDT1, Test1$Species)

set.seed(1001)
fitRF1   <- train(Species ~ ., method = "rf", data = Train1)
#Validate againt the Train data part
predRF1  <- predict(fitRF1, Train1)
table(predRF1, Train1$Species)
#Validate againt the Test data part
testRF1  <- predict(fitRF1, Test1)
table(testRF1, Test1$Species)
```


## Summary 
Misclassifications (Without any parameter tuning)   

* Even split (75/75)

| Model | Decision Tree | Random Forest |
|---+---+---|
| Train | 2 | 0 |
| Test | 5 | 4 |

* 0.8 split (120/30)

| Model | Decision Tree | Random Forest |
|---+---+---|
| Train | 5 | 0 |
| Test | 2 | 1 |
